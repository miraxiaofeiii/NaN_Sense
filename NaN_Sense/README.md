# NaNSense â€” Beauty Comment Intelligence (Lâ€™OrÃ©al Ã— Monash Datathon)

Pipeline for transforming large-scale social/UGC comments into **pillars** (skincare/makeup/haircare/fragrance), **subâ€‘categories** (e.g., Foundation, Serum), **emotions** (joy/neutral/sadness/anger), **consumer pain points** (Price, Packaging, Quality, Availability, Sustainability, Compatibility), plus **QER** (quality engagement ratio) and **trend signals**.

> **Purpose**: help brand/marketing teams see where conversations are growing, which subâ€‘categories & pain points matter, and how emotion + engagement evolve over time.

---

## âœ¨ Key Features

- **Robust ingest**: text normalisation, deâ€‘duplication, ruleâ€‘based spam filter.
- **Weaklyâ€‘supervised spam ML**: HashingVectorizer + SGD, precisionâ€‘tuned threshold.
- **Pillar + subcategory rules**: highâ€‘precision regex over curated beauty dictionary.
- **Emotion inference**: DistilRoBERTa model (`j-hartmann/emotion-english-distilroberta-base`) mapped 6â†’4 labels with a neutral gate.
- **Painâ€‘point tagging (regex)**: conservative patterns to avoid currencyâ€‘only false positives.
- **QER**: combines length normaliser, emotion weight, and logâ€‘likes.
- **Trends**: weekly/monthly â€œzâ€‘burstâ€ term risers per pillar + trendlines.
- **CSV artifacts** for dashboards (categories, pains, trendlines, QER summary).

---

## ğŸ—‚ï¸ Repo Structure

```
.
â”œâ”€ 01_ingest_spam_dedup.py         # normalise â†’ dedup â†’ basic spam rules
â”œâ”€ 01b_spam_ml.py                  # weakly-supervised ML spam classifier
â”œâ”€ 02_pillar_and_emotion_plus.py   # pillars + subcategories + emotions
â”œâ”€ 03_qer_and_trends_plus.py       # QER, trends, pain-points, exports
â”œâ”€ data/                           # (you create) raw & intermediate inputs
â”œâ”€ out_qer/                        # QER summaries
â”œâ”€ out_trends/                     # top risers + trendlines
â”œâ”€ out_categories/                 # category breakdowns
â”œâ”€ out_pain/                       # pain point tables
â””â”€ README.md
```

---

## ğŸ§° Requirements

- Python **3.10+** (tested on 3.10/3.11/3.12)
- Recommended: **CUDAâ€‘enabled GPU** for emotion inference (PyTorch + Transformers)
- Install dependencies:

```bash
pip install -U pandas numpy scikit-learn scipy torch transformers evaluate ftfy pyarrow
```

> **Windows note**: Hugging Face cache symlink warnings are safe. Enable **Developer Mode** for faster caching if desired.

---

## ğŸš€ Quickstart

Assume your cleaned raw comments (CSV/Parquet) live at `data/comments_cleaned.parquet`
with a text column like `clean_text` (scripts autoâ€‘detect from common names).

1) **Ingest + deâ€‘dup + rule spam**
```bash
python 01_ingest_spam_dedup.py --input data/comments_cleaned.parquet --out stage1_clean.parquet
```

2) **Spam ML (weaklyâ€‘supervised)**
```bash
python 01b_spam_ml.py --raw data/comments_cleaned.parquet --clean stage1_clean.parquet \
  --out-prefix stage1b --sample 120000 --target-precision 0.95
# Outputs:
# - stage1b_scored.parquet (raw + scores)
# - stage1b_clean_ml.parquet (final cleaned)
# - out_spam_ml/metrics.txt (AP, chosen threshold, report)
```

3) **Pillars + subcategories + emotions**
```bash
python 02_pillar_and_emotion_plus.py --input stage1b_clean_ml.parquet \
  --out stage2_tagged_plus.parquet --batch-size 192 --max-length 192
```
> GPU autoâ€‘detected. On CPU this step is slower.

4) **QER, Trends, Pain points, Category tables**
```bash
python 03_qer_and_trends_plus.py --input stage2_tagged_plus.parquet --period W --min-df 50
# Exports:
# out_qer/qer_summary.csv
# out_categories/category_breakdown_by_pillar.csv
# out_pain/pain_counts_by_pillar.csv
# out_pain/pain_counts_by_pillar_period.csv
# out_trends/top_risers_by_pillar.csv
# out_trends/term_trendlines.csv
```

---

## ğŸ“¦ Inputs & Outputs

**Inputs**
- Parquet/CSV with a text column (autoâ€‘detected from: `clean_text`, `textOriginal`, `text`, `comment`).
- Optional: `publishedAt`/`created_at` timestamp for trends; `likeCount` for QER.

**Core Output (stage 2)**  
`stage2_tagged_plus.parquet` includes:
- `is_skincare`, `is_makeup`, `is_haircare`, `is_fragrance`
- `pillar_primary`, `category_primary`, `category_all`
- `emotion_base` (joy/neutral/sadness/anger), `emotion_conf`, `p_joy`â€¦`p_anger`
- (plus your original meta like `publishedAt`, `likeCount` if present)

**CSV Artifacts**
- `out_qer/qer_summary.csv` â€” overall and perâ€‘pillar QER mean & counts
- `out_categories/category_breakdown_by_pillar.csv`
- `out_pain/pain_counts_by_pillar.csv` + `_by_pillar_period.csv`
- `out_trends/top_risers_by_pillar.csv`, `term_trendlines.csv`

---

## ğŸ§® Method Details

- **Spam ML**: HashingVectorizer (char 3â€“5, word 1â€“2) â†’ TFâ€‘IDF â†’ SGD (log loss), `class_weight="balanced"`. Threshold tuned for target precision on silver validation.
- **Pillars/Subcats**: curated dictionaries + regex unions; hairâ€‘vsâ€‘skin disambiguation; primary pillar via hit count.
- **Emotions**: `j-hartmann/emotion-english-distilroberta-base` (6 logits) â†’ 4â€‘label mapping with **neutral gate** to reduce neutral drift.
- **Pain points**: **revised** conservative regex â€” currency requires numbers (e.g., `RM59`, `$12`) and/or explicit sentiment cues (â€œtoo expensiveâ€, â€œaffordableâ€). Currencyâ€‘only mentions are **ignored**.
- **QER**: `(length_weight + emotion_weight) * log1p(likes)`; emotion weights: joy=+0.2, neutral=0, sadness=âˆ’0.1, anger=âˆ’0.2.
- **Trends**: weekly/monthly term counts on a fixed vocab; zâ€‘score of term share vs rolling baseline (â€œzâ€‘burstâ€).

---

## ğŸ§ª Evaluation (how to)

- **Spam ML**: inspect `out_spam_ml/metrics.txt` (Average Precision, classification report).
- **Emotions**: (Optional) use your 240â€‘row labelled set to compute accuracy/F1; adjust neutral gate if needed.
- **Pillars/Subcats**: spotâ€‘check precision on random samples; tune dictionaries.
- **Pain points**: verify coverage < 100% and â€œPriceâ€ no longer dominates due to currencyâ€‘only matches.

> Keep a small `notebooks/` folder for sampling and error analysis (FP/FN review).

---

## âš™ï¸ Configuration & Flags

- All scripts support `--help`.
- Common flags:
  - `--period {W,M}` for trends aggregation.
  - `--min-df` minimum document frequency for trend vocab.
  - `--likes-col` (default `likeCount`) for QER.
  - `--batch-size` and `--max-length` for emotion inference.

---

## ğŸ©¹ Troubleshooting

- **Transformers dtype warning**: handled in code; GPU/CPU dtype autoâ€‘set.
- **Windows symlink warning**: safe; enable Developer Mode for faster caching.
- **CUDA not used**: install CUDAâ€‘enabled PyTorch and verify `torch.cuda.is_available()` is `True`.
- **Everything tagged as Price / pain coverage 100%**: ensure youâ€™re on the **revised pain regex** (currencyâ€‘only no longer counts).

---

## ğŸ”’ Data & Privacy

- Donâ€™t commit raw data. Use `.gitignore`:
```
# data & heavy intermediates
data/
*.parquet
out_spam_ml/
__pycache__/
*.ipynb_checkpoints/
```
- Only commit aggregated CSVs that contain no PII.

---

## ğŸ—ºï¸ Roadmap

- Subcategoryâ€‘aware pain mapping (e.g., â€œcakeyâ€ â†’ Makeup/Foundation).
- Lightweight supervised pain classifier using the 240â€‘row set.
- Sarcasm robustness & domainâ€‘adapted emotion fineâ€‘tune.
- Streamlit/Power BI dashboard hooked to `out_*` CSVs.

---

## ğŸ™ Acknowledgements

- Lâ€™OrÃ©al Ã— Monash Datathon organisers & mentors.
- Pretrained model: `j-hartmann/emotion-english-distilroberta-base` (Hugging Face).

---

## ğŸ“« Contact

Questions, bugs, or ideas? Open an issue or reach out via GitHub.
